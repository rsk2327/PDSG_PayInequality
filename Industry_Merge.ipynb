{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_improvement.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEF9mTPhvm61",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: **Data Improvement & Further Analysis**\n",
        "\n",
        "Merging all industry sectors, and analyze based on the merging result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzfbitR4vCzd",
        "colab_type": "code",
        "outputId": "188ead98-ffde-4a3d-cfcb-4a2565cf340e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from collections import defaultdict\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import matplotlib.pyplot as plt  \n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2G8LsX6wZR_",
        "colab_type": "code",
        "outputId": "3e41ca80-d77a-43a0-9314-f5ce2fcea74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfVZ7qrHvk_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(root_dir, data_folder, csv_file):\n",
        "    print(\"\\nReading data from \" + csv_file)\n",
        "    file_dir = os.path.join(root_dir, data_folder, csv_file)\n",
        "    return_df = pd.read_csv(file_dir)\n",
        "    return return_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0t0pgNbwB7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_dataframe(dst_dataframe, new_part):\n",
        "    no_nan_new_part = new_part.copy().fillna('')\n",
        "    if dst_dataframe is None:\n",
        "        dst_dataframe = no_nan_new_part.copy()\n",
        "        return dst_dataframe\n",
        "    else:\n",
        "        dst_dataframe = pd.concat([dst_dataframe, no_nan_new_part])\n",
        "        return dst_dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOO7FDzmEwvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rewrite_industry(all_df, correspond_dict, criterion_dict, name_dict, industry_dict):\n",
        "    rewritten_df = all_df.copy().drop(labels = ['IndustryName', 'IndustrySegmentName', 'IndustrySectorName'], axis = 1)\n",
        "    inv_name_dict = {}\n",
        "    for x in name_dict.items():\n",
        "        inv_name_dict[x[1]] = x[0]\n",
        "\n",
        "    mapping = {}\n",
        "    for company in industry_dict:\n",
        "        temp = list(industry_dict[company].values())\n",
        "        infos = temp[0].split('-')\n",
        "        if len(infos[0].strip()) > 0:\n",
        "            if (len(infos[1]) == 0) and (len(infos[2]) == 0):\n",
        "                if infos[0].strip() in correspond_dict:\n",
        "                    new_class = correspond_dict[infos[0].strip()]\n",
        "                    mapping[company] = inv_name_dict[new_class]\n",
        "            elif (len(infos[1]) > 0) and (len(infos[2]) == 0):\n",
        "                if infos[1].strip() in correspond_dict:\n",
        "                    new_class = correspond_dict[infos[1].strip()]\n",
        "                    mapping[company] = inv_name_dict[new_class]\n",
        "            elif (len(infos[1]) > 0) and (len(infos[2]) > 0):\n",
        "                if infos[2].strip() in correspond_dict:\n",
        "                    new_class = correspond_dict[infos[2].strip()]\n",
        "                    mapping[company] = inv_name_dict[new_class]\n",
        "            \n",
        "\n",
        "    sector = []\n",
        "    sector_name = []\n",
        "    industry_group = []\n",
        "    industry_group_name = []\n",
        "    industry = []\n",
        "    industry_name = []\n",
        "    row_idx = 0\n",
        "    while row_idx < all_df.shape[0]:\n",
        "        company_kfid = str(all_df.iloc[row_idx, 1])\n",
        "        if company_kfid in mapping:\n",
        "            serial_num = str(mapping[company_kfid])\n",
        "            if len(serial_num) == 2:\n",
        "                sector.append(serial_num)\n",
        "                sector_name.append(name_dict[serial_num])\n",
        "                industry_group.append('')\n",
        "                industry_group_name.append('')\n",
        "                industry.append('')\n",
        "                industry_name.append('')\n",
        "            elif len(serial_num) == 4:\n",
        "                sector.append(serial_num[:2])\n",
        "                sector_name.append(name_dict[serial_num[:2]])\n",
        "                industry_group.append(serial_num)\n",
        "                industry_group_name.append(name_dict[serial_num])\n",
        "                industry.append('')\n",
        "                industry_name.append('')\n",
        "            elif len(serial_num) == 6:\n",
        "                sector.append(serial_num[:2])\n",
        "                sector_name.append(name_dict[serial_num[:2]])\n",
        "                industry_group.append(serial_num[:4])\n",
        "                industry_group_name.append(name_dict[serial_num[:4]])\n",
        "                industry.append(serial_num)\n",
        "                industry_name.append(name_dict[serial_num])\n",
        "            elif len(serial_num) == 8:\n",
        "                sector.append(serial_num[:2])\n",
        "                sector_name.append(name_dict[serial_num[:2]])\n",
        "                industry_group.append(serial_num[:4])\n",
        "                industry_group_name.append(name_dict[serial_num[:4]])\n",
        "                industry.append(serial_num[:6])\n",
        "                industry_name.append(name_dict[serial_num[:6]])\n",
        "        else:\n",
        "            sector.append('')\n",
        "            sector_name.append('')\n",
        "            industry_group.append('')\n",
        "            industry_group_name.append('')\n",
        "            industry.append('')\n",
        "            industry_name.append('')\n",
        "        row_idx += 1\n",
        "\n",
        "    rewritten_df['SectorNumber'] = sector\n",
        "    rewritten_df['SectorName'] = sector_name\n",
        "    rewritten_df['IndustryGroupNumber'] = industry_group\n",
        "    rewritten_df['IndustryGroupName'] = industry_group_name\n",
        "    rewritten_df['IndustryNumber'] = industry\n",
        "    rewritten_df['IndustryName'] = industry_name\n",
        "\n",
        "    return rewritten_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORWL1eVQwED5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Basic environ params\n",
        "'''\n",
        "# root_dir = \"\\\\\".join(os.path.dirname(__file__).split('\\\\')[:-1])\n",
        "root_dir = '/content/drive/My Drive/Penn Inequality Project'\n",
        "data_folder = \"reduced_paynet_data\"\n",
        "task_folder = \"task2\"\n",
        "data_dir = os.path.join(root_dir, data_folder)\n",
        "\n",
        "'''\n",
        "Main adjustable params\n",
        "'''\n",
        "# Section of codes, which are listed in every cell\n",
        "data_merged = True\n",
        "industry_merged = True\n",
        "industry_reclassified = True\n",
        "data_rewritten = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M2dIBOBwKrL",
        "colab_type": "code",
        "outputId": "630e1fc3-c570-49da-fda7-474e2f6eef1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "'''\n",
        "Merge data into one csv\n",
        "'''\n",
        "\n",
        "all_df = None\n",
        "\n",
        "if not data_merged:\n",
        "    print('Merging all csv files together')\n",
        "    for csv_file in os.listdir(data_dir):\n",
        "        df = read_data(root_dir, data_folder, csv_file)\n",
        "        all_df = merge_dataframe(all_df, df)\n",
        "    all_df.to_csv(os.path.join(root_dir, 'all_data.csv'))\n",
        "    print('All csv files are merged\\n')\n",
        "else:\n",
        "    print('Reading merged csv files')\n",
        "    all_df = pd.read_csv(os.path.join(root_dir, 'all_data.csv'))\n",
        "    print('Including ' + str(all_df.shape[0]) + ' data pieces')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading merged csv files\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Including 28397806 data pieces\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Pu9Oe0wzma",
        "colab_type": "code",
        "outputId": "08092590-a4c5-4e92-a8ae-e898de2534f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Merge all industry names based on company and year\n",
        "'''\n",
        "industry_dict = None\n",
        "\n",
        "if not industry_merged:\n",
        "    print('Merging all industry together')\n",
        "    industry_dict = defaultdict(dict)\n",
        "\n",
        "    # key: KF_ID, value: dict of year -- industry_info\n",
        "    all_companies = pd.unique(all_df['KF_ID'])\n",
        "    all_years = pd.unique(all_df['CalendarYear'])\n",
        "    for company in sorted(all_companies):\n",
        "        company_df = all_df[all_df['KF_ID'] == company]\n",
        "        for year in sorted(all_years):\n",
        "            year_company_df = company_df[company_df['CalendarYear'] == year]\n",
        "            if year_company_df.shape[0] > 0:\n",
        "                info = year_company_df[['IndustryName', 'IndustrySegmentName', 'IndustrySectorName']].drop_duplicates()\n",
        "                for row_idx in range(info.shape[0]):\n",
        "                    # remove special character, multiple spaces, lowercase the string, and remove parenthesis\n",
        "                    row = info.iloc[row_idx, :]\n",
        "                    industry_name = re.sub(r'\\(.*\\)', '', str(row['IndustryName']))\n",
        "                    industry_name = re.sub(r'\\W', ' ', industry_name)\n",
        "                    industry_name = re.sub(r' +', ' ', industry_name).lower()\n",
        "                    if len(industry_name) > 0:\n",
        "                        result = []\n",
        "                        for word in re.split(' ', industry_name):\n",
        "                            result.append(lemmatizer.lemmatize(word))\n",
        "                        industry_name = (' '.join(result)).strip()\n",
        "\n",
        "                    industry_segment_name = re.sub(r'\\(.*\\)', '', str(row['IndustrySegmentName']))\n",
        "                    industry_segment_name = re.sub(r'\\W', ' ', industry_segment_name)\n",
        "                    industry_segment_name = re.sub(r' +', ' ', industry_segment_name).lower()\n",
        "                    if len(industry_segment_name) > 0:\n",
        "                        result = []\n",
        "                        for word in re.split(' ', industry_segment_name):\n",
        "                            result.append(lemmatizer.lemmatize(word))\n",
        "                        industry_segment_name = (' '.join(result)).strip()\n",
        "\n",
        "                    industry_sector_name = re.sub(r'\\(.*\\)', '', str(row['IndustrySectorName']))\n",
        "                    industry_sector_name = re.sub(r'\\W', ' ', industry_sector_name)\n",
        "                    industry_sector_name = re.sub(r' +', ' ', industry_sector_name).lower()\n",
        "                    if len(industry_sector_name) > 0:\n",
        "                        result = []\n",
        "                        for word in re.split(' ', industry_sector_name):\n",
        "                            result.append(lemmatizer.lemmatize(word))\n",
        "                        industry_sector_name = (' '.join(result)).strip()\n",
        "\n",
        "                    industry_dict[str(company)][str(year)] = industry_name + '-' + industry_segment_name + '-' + industry_sector_name\n",
        "    with open(os.path.join(root_dir, task_folder, 'industry_original_dict.json'), 'w') as output_file:\n",
        "        json.dump(industry_dict, output_file)\n",
        "else:\n",
        "    print('Reading merged company files')\n",
        "    with open(os.path.join(root_dir, task_folder, 'industry_original_dict.json'), 'r') as input_file:\n",
        "        industry_dict = json.load(input_file)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading merged company files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udKSQMmH72cF",
        "colab_type": "code",
        "outputId": "c49d604a-397d-46bd-a298-4db509d25ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Reclassify industry\n",
        "'''\n",
        "\n",
        "name_dict = None\n",
        "criterion_dict = None\n",
        "correspond_dict = None\n",
        "\n",
        "if not industry_reclassified:\n",
        "    print(\"Reading new classification criterion\")\n",
        "    criterion = pd.read_excel(os.path.join(root_dir, task_folder, 'GICS_map 2018.xlsx')).drop(index = [0,1,2, 3]).fillna(value = -1)\n",
        "    criterion_dict = {}\n",
        "    name_dict = {}\n",
        "    for row_idx in range(criterion.shape[0]):\n",
        "        row = criterion.iloc[row_idx, :]\n",
        "        sector = str(row[0])\n",
        "        industry_group = str(row[2])\n",
        "        industry = str(row[4])\n",
        "        sub_industry = str(row[6]) \n",
        "\n",
        "        # remove special character, multiple spaces, and lowercase the string \n",
        "        if int(sector) > 0:\n",
        "            criterion_dict[sector] = {}\n",
        "            sector_name = re.sub(r'&', ' and ', row[1])\n",
        "            sector_name = re.sub(r'\\W', ' ', sector_name)\n",
        "            sector_name = re.sub(r' +', ' ', sector_name).lower()\n",
        "            temp = []\n",
        "            for word in re.split(' ', sector_name):\n",
        "                temp.append(lemmatizer.lemmatize(word))\n",
        "            sector_name = ' '.join(temp)\n",
        "            name_dict[sector] = re.sub('health care', 'healthcare', sector_name).strip()\n",
        "        if int(industry_group) > 0:\n",
        "            criterion_dict[industry_group[:2]][industry_group] = {}\n",
        "            industry_group_name = re.sub(r'&', ' and ', row[3])\n",
        "            industry_group_name = re.sub(r'\\W', ' ', industry_group_name)\n",
        "            industry_group_name = re.sub(r' +', ' ', industry_group_name).lower()\n",
        "            temp = []\n",
        "            for word in re.split(' ', industry_group_name):\n",
        "                temp.append(lemmatizer.lemmatize(word))\n",
        "            industry_group_name = ' '.join(temp)\n",
        "            name_dict[industry_group] = re.sub('health care', 'healthcare', industry_group_name).strip()\n",
        "        if int(industry) > 0:\n",
        "            criterion_dict[industry[:2]][industry[:4]][industry] = {}\n",
        "            industry_name = re.sub(r'&', ' and ', row[5])\n",
        "            industry_name = re.sub(r'\\W', ' ', industry_name)\n",
        "            industry_name = re.sub(r' +', ' ', industry_name).lower()\n",
        "            temp = []\n",
        "            for word in re.split(' ', industry_name):\n",
        "                temp.append(lemmatizer.lemmatize(word))\n",
        "            industry_name = ' '.join(temp)\n",
        "            name_dict[industry] = re.sub('health care', 'healthcare', industry_name).strip()\n",
        "        if int(sub_industry) > 0:\n",
        "            criterion_dict[sub_industry[:2]][sub_industry[:4]][sub_industry[:6]] = sub_industry\n",
        "            sub_industry_name = re.sub(r'&', ' and ', row[7])\n",
        "            sub_industry_name = re.sub(r'\\W', ' ', sub_industry_name)\n",
        "            sub_industry_name = re.sub(r' +', ' ', sub_industry_name).lower()\n",
        "            temp = []\n",
        "            for word in re.split(' ', sub_industry_name):\n",
        "                temp.append(lemmatizer.lemmatize(word))\n",
        "            sub_industry_name = ' '.join(temp)\n",
        "            name_dict[sub_industry] = re.sub('health care', 'healthcare', sub_industry_name).strip()\n",
        "    print(\"\\nSaving criterion and name into json files\")\n",
        "    with open(os.path.join(root_dir, task_folder, 'name_dict.json'), 'w') as output_file:  \n",
        "        json.dump(name_dict, output_file)\n",
        "    with open(os.path.join(root_dir, task_folder, 'criterion_dict.json'), 'w') as output_file:   \n",
        "        json.dump(criterion_dict, output_file)\n",
        "\n",
        "\n",
        "    print(\"\\nReading given samples of classification\")\n",
        "    samples = pd.read_csv(os.path.join(root_dir, task_folder, 'xpf_financials_masked.csv')).iloc[:, :2].drop_duplicates()\n",
        "    sample_dict = {}\n",
        "    for x in samples.to_numpy():\n",
        "        info = re.sub(r'\\W', ' ', x[1])\n",
        "        info = re.sub(r' +', ' ', info).lower()\n",
        "        temp = []\n",
        "        for word in re.split(' ', info):\n",
        "            temp.append(lemmatizer.lemmatize(word))\n",
        "        sample_dict[str(x[0])] = (' '.join(temp)).strip()\n",
        "    \n",
        "    print(\"\\nFinding replacements in orginal classifcation\")\n",
        "    source_dict = defaultdict(list)\n",
        "    for company in industry_dict:\n",
        "        if company in list(sample_dict.keys()):\n",
        "            for year in industry_dict[company]:\n",
        "                infos = re.split('-', industry_dict[company][year])\n",
        "                if len(infos[0].strip()) > 0:\n",
        "                    if (len(infos[1]) == 0) and (len(infos[2]) == 0):\n",
        "                        source_dict[infos[0].strip()].append(sample_dict[company])\n",
        "                    elif (len(infos[1]) > 0) and (len(infos[2]) == 0):\n",
        "                        source_dict[infos[1].strip()].append(sample_dict[company])\n",
        "                    elif (len(infos[1]) > 0) and (len(infos[2]) > 0):\n",
        "                        source_dict[infos[2].strip()].append(sample_dict[company])\n",
        "    \n",
        "    # vote, select the one with maximum appearence\n",
        "    correspond_dict = {}\n",
        "    for info in source_dict:\n",
        "        args, counts = np.unique(source_dict[info], return_counts=True)\n",
        "        correspond_dict[info] = args[np.argmax(counts)]\n",
        "    \n",
        "    partial_company = set()\n",
        "    for company in industry_dict:\n",
        "        for year in industry_dict[company]:\n",
        "            infos = re.split('-', industry_dict[company][year])\n",
        "            for info in infos:\n",
        "                if info in correspond_dict:\n",
        "                    partial_company.add(company)\n",
        "    \n",
        "    # Non-replacements in original data\n",
        "    print(\"\\nManually replace the company without correpsonding reclassification\")\n",
        "    rest_company = set()\n",
        "    for x in industry_dict.keys():\n",
        "        if x not in partial_company:\n",
        "            rest_company.add(x)\n",
        "    print(str(len(rest_company)) + \" companies are not given proper classes\") \n",
        "    print(\"These KFIDs are listed: \" + str(sorted(list(rest_company))))\n",
        "    # correspond_dict = manual_reclassify(correspond_dict, rest_company)\n",
        "    with open(os.path.join(root_dir, task_folder, 'correspond_dict.json'), 'w') as output_file:   \n",
        "        json.dump(correspond_dict, output_file)\n",
        "\n",
        "else:\n",
        "    print(\"Reading dictionaries for reclassification\")\n",
        "    with open(os.path.join(root_dir, task_folder, 'name_dict.json'), 'r') as input_file:  \n",
        "        name_dict = json.load(input_file)\n",
        "    with open(os.path.join(root_dir, task_folder, 'criterion_dict.json'), 'r') as input_file:   \n",
        "        criterion_dict = json.load(input_file)\n",
        "    with open(os.path.join(root_dir, task_folder, 'correspond_dict.json'), 'r') as input_file:  \n",
        "        correspond_dict = json.load(input_file)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading dictionaries for reclassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5xBYOak7tMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Rewrite into csv file\n",
        "'''\n",
        "\n",
        "if not data_rewritten:\n",
        "    rewritten_df = rewrite_industry(all_df, correspond_dict, criterion_dict, name_dict, industry_dict)\n",
        "    rewritten_df.to_csv(os.path.join(root_dir, 'reclassified_all_data.csv'))\n",
        "else:\n",
        "    rewritten_df = pd.read_csv(os.path.join(root_dir, 'reclassified_all_data.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39HKdg5ldhsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
